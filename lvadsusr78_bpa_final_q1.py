# -*- coding: utf-8 -*-
"""LVADSUSR78_BPA_final-Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13IVT2uQ8YV1RaugfBNk-J2ajPLDHGCcn
"""

from google.colab import drive
drive.mount("/content/drive")

# Commented out IPython magic to ensure Python compatibility.
#1
import warnings
warnings.filterwarnings("ignore")
from sklearn.cluster import KMeans
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from matplotlib import pyplot as plt
import seaborn as sns
# %matplotlib inline

# readcsv data
loan_data = pd.read_csv("/content/drive/MyDrive/loan_approval.csv")
loan_data.head()

#visualize correl
correl = loan_data.corr()
print(correl)
sns.heatmap(correl, annot=True, fmt = '0.2f')

loan_data.info()

loan_data.isnull().sum()

loan_data.drop_duplicates()

# encoding categorical data
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
loan_data[' education'] = encoder.fit_transform(loan_data[' education'])
loan_data[' self_employed'] = encoder.fit_transform(loan_data[' self_employed'])
loan_data[' loan_status'] = encoder.fit_transform(loan_data[' loan_status'])

loan_data.head()

# normalizing data using minmaxscaler

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
loan_data[' income_annum'] = scaler.fit_transform(loan_data[[' income_annum']])
loan_data[' loan_amount'] = scaler.fit_transform(loan_data[[' loan_amount']])
loan_data[' residential_assets_value'] = scaler.fit_transform(loan_data[[' residential_assets_value']])
loan_data[' commercial_assets_value'] = scaler.fit_transform(loan_data[[' commercial_assets_value']])
loan_data[' luxury_assets_value'] = scaler.fit_transform(loan_data[[' luxury_assets_value']])
loan_data[' bank_asset_value'] = scaler.fit_transform(loan_data[[' bank_asset_value']])

loan_data.head()

# building model

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score

x = loan_data.drop([' loan_status'], axis = 1)
y = loan_data[' loan_status']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)

model = RandomForestClassifier()
model.fit(x_train, y_train)
y_pred = model.predict(x_test)

print("Accuracy score :", accuracy_score(y_test, y_pred)*100 )
print("Precision score :", precision_score(y_test, y_pred) )
print("Recall score :", recall_score(y_test, y_pred) )
print("F1 score :", f1_score(y_test, y_pred) )

matrix = confusion_matrix(y_test, y_pred)
print(matrix)

# xgboost model
from xgboost import XGBClassifier
import math

xg_model = XGBClassifier()
xg_model.fit(x_train, y_train)
y_pred = xg_model.predict(x_test)

print("Using XGBoost Classifier : ")
print("Accuracy score :", accuracy_score(y_test, y_pred)*100 )
print("Precision score :", precision_score(y_test, y_pred) )
print("Recall score :", recall_score(y_test, y_pred) )
print("F1 score :", f1_score(y_test, y_pred) )

# decision tree model
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(x_train, y_train)
y_pred = model.predict(x_test)

print("Using Decision Tree Classifier : ")
print("Accuracy score :", accuracy_score(y_test, y_pred)*100 )
print("Precision score :", precision_score(y_test, y_pred) )
print("Recall score :", recall_score(y_test, y_pred) )
print("F1 score :", f1_score(y_test, y_pred) )